"""
Ejemplo de uso del Sistema Autopoi√©tico con Cloudflare Workers AI.

Este ejemplo muestra c√≥mo usar Cloudflare Workers AI como backend LLM
en lugar de OpenAI, lo cual es m√°s econ√≥mico.
"""

import sys
from pathlib import Path
import os

# A√±adir src al path
repo_root = Path(__file__).parent.parent
sys.path.insert(0, str(repo_root / "src"))

from query_llm import create_cloudflare_llm, CLOUDFLARE_MODELS
from dotenv import load_dotenv

load_dotenv()


def ejemplo_basico_cloudflare():
    """
    Ejemplo b√°sico de uso directo del LLM de Cloudflare.
    """
    print("\n" + "="*80)
    print("EJEMPLO 1: Uso B√°sico de Cloudflare Workers AI")
    print("="*80)
    
    # Crear LLM de Cloudflare
    llm = create_cloudflare_llm(
        model="llama-2-7b",  # Modelo econ√≥mico y r√°pido
        temperature=0.7
    )
    
    # Test simple
    print("\nüìù Pregunta: ¬øQu√© es Python?")
    respuesta = llm.invoke("Explica qu√© es Python en una oraci√≥n.")
    print(f"\nü§ñ Respuesta: {respuesta}")


def ejemplo_modelos_disponibles():
    """
    Muestra los modelos disponibles en Cloudflare Workers AI.
    """
    print("\n" + "="*80)
    print("EJEMPLO 2: Modelos Disponibles en Cloudflare")
    print("="*80)
    
    print("\nüìã Modelos de chat disponibles:")
    print("-" * 80)
    
    for nombre, modelo_id in CLOUDFLARE_MODELS.items():
        tipo = "Chat/Texto" if "chat" in modelo_id or "instruct" in modelo_id else "Embeddings"
        print(f"  ‚Ä¢ {nombre:15} ‚Üí {modelo_id:50} [{tipo}]")
    
    print("\nüí° Tip: Los modelos m√°s peque√±os (tinyllama) son m√°s r√°pidos")
    print("        Los modelos m√°s grandes (llama-2-13b) son m√°s precisos")


def ejemplo_comparacion_modelos():
    """
    Compara respuestas de diferentes modelos de Cloudflare.
    """
    print("\n" + "="*80)
    print("EJEMPLO 3: Comparaci√≥n de Modelos")
    print("="*80)
    
    pregunta = "¬øQu√© son los principios SOLID en programaci√≥n?"
    
    modelos_a_probar = ["tinyllama", "llama-2-7b", "mistral-7b"]
    
    for modelo in modelos_a_probar:
        if modelo not in CLOUDFLARE_MODELS:
            continue
        
        print(f"\nüîπ Modelo: {modelo}")
        print("-" * 80)
        
        try:
            llm = create_cloudflare_llm(model=modelo, temperature=0.3)
            respuesta = llm.invoke(pregunta)
            print(f"Respuesta: {respuesta[:300]}...")
        except Exception as e:
            print(f"‚ùå Error: {str(e)}")


def ejemplo_con_orquestador():
    """
    Integra Cloudflare Workers AI con el sistema autopoi√©tico.
    """
    print("\n" + "="*80)
    print("EJEMPLO 4: Cloudflare con Sistema Autopoi√©tico")
    print("="*80)
    
    # NOTA: Para usar Cloudflare con el orquestador, necesitamos
    # modificar la implementaci√≥n para aceptar LLMs personalizados
    
    print("\nüìù Para integrar Cloudflare con el orquestador:")
    print("""
    1. El orquestador actual usa ChatOpenAI de LangChain
    2. Para usar Cloudflare, necesitamos pasar CloudflareLLM personalizado
    3. Esto requiere modificar AutopoieticOrchestrator para aceptar llm_instance
    
    Ejemplo futuro:
    
        from src.query_llm import create_cloudflare_llm
        from src.autopoietic_orchestrator import AutopoieticOrchestrator
        
        # Crear LLM de Cloudflare
        llm = create_cloudflare_llm(model="llama-2-7b")
        
        # Crear orquestador con LLM personalizado
        orchestrator = AutopoieticOrchestrator(llm_instance=llm)
        
        # Usar normalmente
        result = orchestrator.invoke("Organizar viaje de windsurf")
    """)


def ejemplo_costo_comparativo():
    """
    Muestra la comparaci√≥n de costos entre proveedores.
    """
    print("\n" + "="*80)
    print("EJEMPLO 5: Comparaci√≥n de Costos")
    print("="*80)
    
    print("""
    üí∞ COMPARACI√ìN DE COSTOS (aproximados):
    
    OpenAI GPT-4:
      - Input: $0.03 / 1K tokens
      - Output: $0.06 / 1K tokens
      - Promedio: ~$0.05 / request
    
    Cloudflare Workers AI:
      - Modelo Llama 2: $0.00001 / 1K tokens
      - Modelo Mistral: $0.00001 / 1K tokens
      - Promedio: ~$0.0001 / request
      
    LM Studio (Local):
      - Costo: $0 (gratis)
      - Requisito: GPU/CPU local
    
    üìä Cloudflare es ~500x m√°s barato que OpenAI
    üìä LM Studio es gratis pero requiere hardware local
    """)


def test_conexion_cloudflare():
    """
    Verifica que las credenciales de Cloudflare est√©n configuradas.
    """
    print("\n" + "="*80)
    print("TEST: Verificaci√≥n de Credenciales Cloudflare")
    print("="*80)
    
    account_id = os.getenv("CLOUDFLARE_ACCOUNT_ID")
    auth_token = os.getenv("CLOUDFLARE_AUTH_TOKEN")
    
    print("\nüîç Verificando configuraci√≥n...")
    
    if not account_id:
        print("‚ùå CLOUDFLARE_ACCOUNT_ID no configurado en .env")
        print("   Obt√©n tu Account ID en: https://dash.cloudflare.com")
    else:
        print(f"‚úÖ CLOUDFLARE_ACCOUNT_ID: {account_id[:8]}...")
    
    if not auth_token:
        print("‚ùå CLOUDFLARE_AUTH_TOKEN no configurado en .env")
        print("   Crea un token en: https://dash.cloudflare.com/profile/api-tokens")
    else:
        print(f"‚úÖ CLOUDFLARE_AUTH_TOKEN: {auth_token[:8]}...")
    
    if account_id and auth_token:
        print("\n‚úÖ Credenciales configuradas correctamente")
        print("\nüß™ Probando conexi√≥n...")
        
        try:
            llm = create_cloudflare_llm(model="tinyllama", temperature=0.5)
            respuesta = llm.invoke("Di 'Hola'")
            print(f"\nüéâ ¬°Conexi√≥n exitosa!")
            print(f"üìù Respuesta de prueba: {respuesta}")
        except Exception as e:
            print(f"\n‚ùå Error al conectar: {str(e)}")
            print("\nVerifica que:")
            print("  1. Las credenciales sean correctas")
            print("  2. Tengas acceso a Workers AI en tu cuenta")
            print("  3. Tu conexi√≥n a internet est√© activa")
    else:
        print("\n‚ö†Ô∏è  Configura tus credenciales en .env para continuar")


def guia_configuracion():
    """
    Gu√≠a paso a paso para configurar Cloudflare Workers AI.
    """
    print("\n" + "="*80)
    print("GU√çA: C√≥mo Configurar Cloudflare Workers AI")
    print("="*80)
    
    print("""
    üìö PASOS PARA CONFIGURAR CLOUDFLARE WORKERS AI:
    
    1Ô∏è‚É£  CREAR CUENTA EN CLOUDFLARE:
       - Ve a: https://dash.cloudflare.com
       - Reg√≠strate o inicia sesi√≥n
       - Es gratis para empezar
    
    2Ô∏è‚É£  OBTENER ACCOUNT ID:
       - En el dashboard, ve a cualquier secci√≥n
       - El Account ID aparece en la barra lateral
       - C√≥pialo y gu√°rdalo
    
    3Ô∏è‚É£  CREAR API TOKEN:
       - Ve a: https://dash.cloudflare.com/profile/api-tokens
       - Click en "Create Token"
       - Selecciona "Edit Cloudflare Workers" template
       - O crea un Custom Token con permisos de Workers AI
       - Copia el token (solo se muestra una vez)
    
    4Ô∏è‚É£  CONFIGURAR .ENV:
       - Abre el archivo .env en tu proyecto
       - A√±ade:
         CLOUDFLARE_ACCOUNT_ID=tu-account-id-aqui
         CLOUDFLARE_AUTH_TOKEN=tu-token-aqui
    
    5Ô∏è‚É£  PROBAR CONEXI√ìN:
       - Ejecuta: python examples/cloudflare_usage.py
       - El test verificar√° tu configuraci√≥n
    
    üí° TIPS:
       - Workers AI tiene un free tier generoso
       - Los modelos peque√±os (tinyllama) son ideales para desarrollo
       - Usa modelos grandes (llama-2-13b) solo para producci√≥n
       - Cloudflare tiene latencia baja (edge computing)
    
    üìñ Documentaci√≥n oficial:
       https://developers.cloudflare.com/workers-ai/
    """)


if __name__ == "__main__":
    print("\n" + "üå©Ô∏è "*40)
    print("EJEMPLOS DE USO: CLOUDFLARE WORKERS AI")
    print("üå©Ô∏è "*40)
    
    # Ejecutar todos los ejemplos
    # Comenta/descomenta seg√∫n lo que quieras probar
    
    # test_conexion_cloudflare()  # Empieza por aqu√≠
    # guia_configuracion()
    # ejemplo_modelos_disponibles()
    # ejemplo_basico_cloudflare()
    # ejemplo_comparacion_modelos()
    # ejemplo_costo_comparativo()
    
    # Por defecto, mostrar la gu√≠a
    print("\nüìã Ejecutando: Verificaci√≥n + Gu√≠a de Configuraci√≥n\n")
    test_conexion_cloudflare()
    guia_configuracion()
    
    print("\n" + "‚úÖ"*40)
    print("FIN DE EJEMPLOS")
    print("‚úÖ"*40 + "\n")
